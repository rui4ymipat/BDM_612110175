{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":152,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('https://raw.githubusercontent.com/plenoi/CMU_DataScience/master/lung.csv?fbclid=IwAR10csOwLfZjAp7Q2afBuRXDrUwRANq50diSFD4h4vhQ8E_etAZiC_K05B8',header=None)\ndf","execution_count":153,"outputs":[{"output_type":"execute_result","execution_count":153,"data":{"text/plain":"     0         1         2         3         4         5         6     \\\n0       1 -0.953518 -0.433265 -0.926334 -0.878343 -0.940477 -0.881761   \n1       1 -0.976293 -0.750423 -0.941069 -0.980535 -0.994048 -0.925679   \n2       1 -0.663669 -0.491751 -0.893186 -0.854013 -0.934524 -0.842909   \n3       1 -0.852158 -0.730928 -0.697973 -0.970803 -0.928571 -0.940880   \n4       1 -0.987727 -0.858310 -0.985267 -0.975669 -1.000000 -0.988176   \n..    ...       ...       ...       ...       ...       ...       ...   \n627     0 -0.938026 -0.324072 -0.871086 -0.367380 -0.755951 -0.505091   \n628     0 -0.930654 -0.361768 -0.933701 -0.902674 -0.976190 -0.937502   \n629     0 -0.905128 -0.149886 -0.882138 -0.751823 -0.940477 -0.896964   \n630     0 -0.985533 -0.799825 -0.996317 -0.970803 -0.994048 -0.998311   \n631     0 -0.985393 -0.815414 -0.985267 -0.995134 -1.000000 -0.994933   \n\n         7         8         9     ...      1271      1272      1273  \\\n0   -0.555303 -0.866727 -0.339190  ...  0.111509 -0.842061 -0.984096   \n1   -0.844926 -0.942945 -0.778852  ...  0.256599 -0.918326 -0.997074   \n2   -0.792472 -0.907733 -0.490566  ...  0.184607 -0.844687 -0.969846   \n3   -0.621438 -0.958102 -0.739355  ...  0.496361 -0.900450 -0.989313   \n4   -0.908780 -0.938043 -0.861778  ...  0.565058 -0.545379 -0.996183   \n..        ...       ...       ...  ...       ...       ...       ...   \n627 -0.582674 -0.966124 -0.377365  ... -0.237275 -0.893069 -0.995038   \n628 -0.603191 -0.728547 -0.291794  ...  0.555847 -0.403511 -0.934094   \n629 -0.290764 -0.691552 -0.118042  ...  0.469137 -0.357597 -0.914628   \n630 -0.872292 -0.915757 -0.809127  ...  0.732931 -0.573425 -0.970355   \n631 -0.879133 -0.926900 -0.815704  ...  0.714058 -0.585071 -0.978370   \n\n         1274      1275      1276      1277      1278      1279      1280  \n0   -0.641238 -0.611943 -0.852940 -0.891501 -0.737089 -0.879686 -0.998865  \n1   -0.912676 -0.895525 -0.985294 -0.945752 -0.768386 -0.942223 -0.999525  \n2   -0.038363 -0.425380 -0.887256 -0.938516 -0.729780 -0.903817 -0.979734  \n3   -0.681212 -0.701494 -0.936275 -0.978300 -0.814291 -0.920470 -0.992083  \n4   -0.910572 -0.880595 -0.990196 -1.000000 -0.854985 -0.555620 -0.988864  \n..        ...       ...       ...       ...       ...       ...       ...  \n627 -0.930562 -0.873133 -0.877452 -0.938516 -0.806991 -0.857425 -0.998654  \n628 -0.545495 -0.679108 -0.877452 -0.927667 -0.845587 -0.432757 -0.974535  \n629 -0.360328 -0.485076 -0.818625 -0.905969 -0.832032 -0.350340 -0.970445  \n630 -0.815885 -0.865671 -0.921566 -0.992767 -0.880016 -0.598787 -0.972266  \n631 -0.862177 -0.746272 -0.916665 -0.992767 -0.883149 -0.633289 -0.968412  \n\n[632 rows x 1281 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1271</th>\n      <th>1272</th>\n      <th>1273</th>\n      <th>1274</th>\n      <th>1275</th>\n      <th>1276</th>\n      <th>1277</th>\n      <th>1278</th>\n      <th>1279</th>\n      <th>1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-0.953518</td>\n      <td>-0.433265</td>\n      <td>-0.926334</td>\n      <td>-0.878343</td>\n      <td>-0.940477</td>\n      <td>-0.881761</td>\n      <td>-0.555303</td>\n      <td>-0.866727</td>\n      <td>-0.339190</td>\n      <td>...</td>\n      <td>0.111509</td>\n      <td>-0.842061</td>\n      <td>-0.984096</td>\n      <td>-0.641238</td>\n      <td>-0.611943</td>\n      <td>-0.852940</td>\n      <td>-0.891501</td>\n      <td>-0.737089</td>\n      <td>-0.879686</td>\n      <td>-0.998865</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.976293</td>\n      <td>-0.750423</td>\n      <td>-0.941069</td>\n      <td>-0.980535</td>\n      <td>-0.994048</td>\n      <td>-0.925679</td>\n      <td>-0.844926</td>\n      <td>-0.942945</td>\n      <td>-0.778852</td>\n      <td>...</td>\n      <td>0.256599</td>\n      <td>-0.918326</td>\n      <td>-0.997074</td>\n      <td>-0.912676</td>\n      <td>-0.895525</td>\n      <td>-0.985294</td>\n      <td>-0.945752</td>\n      <td>-0.768386</td>\n      <td>-0.942223</td>\n      <td>-0.999525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-0.663669</td>\n      <td>-0.491751</td>\n      <td>-0.893186</td>\n      <td>-0.854013</td>\n      <td>-0.934524</td>\n      <td>-0.842909</td>\n      <td>-0.792472</td>\n      <td>-0.907733</td>\n      <td>-0.490566</td>\n      <td>...</td>\n      <td>0.184607</td>\n      <td>-0.844687</td>\n      <td>-0.969846</td>\n      <td>-0.038363</td>\n      <td>-0.425380</td>\n      <td>-0.887256</td>\n      <td>-0.938516</td>\n      <td>-0.729780</td>\n      <td>-0.903817</td>\n      <td>-0.979734</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-0.852158</td>\n      <td>-0.730928</td>\n      <td>-0.697973</td>\n      <td>-0.970803</td>\n      <td>-0.928571</td>\n      <td>-0.940880</td>\n      <td>-0.621438</td>\n      <td>-0.958102</td>\n      <td>-0.739355</td>\n      <td>...</td>\n      <td>0.496361</td>\n      <td>-0.900450</td>\n      <td>-0.989313</td>\n      <td>-0.681212</td>\n      <td>-0.701494</td>\n      <td>-0.936275</td>\n      <td>-0.978300</td>\n      <td>-0.814291</td>\n      <td>-0.920470</td>\n      <td>-0.992083</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>-0.987727</td>\n      <td>-0.858310</td>\n      <td>-0.985267</td>\n      <td>-0.975669</td>\n      <td>-1.000000</td>\n      <td>-0.988176</td>\n      <td>-0.908780</td>\n      <td>-0.938043</td>\n      <td>-0.861778</td>\n      <td>...</td>\n      <td>0.565058</td>\n      <td>-0.545379</td>\n      <td>-0.996183</td>\n      <td>-0.910572</td>\n      <td>-0.880595</td>\n      <td>-0.990196</td>\n      <td>-1.000000</td>\n      <td>-0.854985</td>\n      <td>-0.555620</td>\n      <td>-0.988864</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>0</td>\n      <td>-0.938026</td>\n      <td>-0.324072</td>\n      <td>-0.871086</td>\n      <td>-0.367380</td>\n      <td>-0.755951</td>\n      <td>-0.505091</td>\n      <td>-0.582674</td>\n      <td>-0.966124</td>\n      <td>-0.377365</td>\n      <td>...</td>\n      <td>-0.237275</td>\n      <td>-0.893069</td>\n      <td>-0.995038</td>\n      <td>-0.930562</td>\n      <td>-0.873133</td>\n      <td>-0.877452</td>\n      <td>-0.938516</td>\n      <td>-0.806991</td>\n      <td>-0.857425</td>\n      <td>-0.998654</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>0</td>\n      <td>-0.930654</td>\n      <td>-0.361768</td>\n      <td>-0.933701</td>\n      <td>-0.902674</td>\n      <td>-0.976190</td>\n      <td>-0.937502</td>\n      <td>-0.603191</td>\n      <td>-0.728547</td>\n      <td>-0.291794</td>\n      <td>...</td>\n      <td>0.555847</td>\n      <td>-0.403511</td>\n      <td>-0.934094</td>\n      <td>-0.545495</td>\n      <td>-0.679108</td>\n      <td>-0.877452</td>\n      <td>-0.927667</td>\n      <td>-0.845587</td>\n      <td>-0.432757</td>\n      <td>-0.974535</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>0</td>\n      <td>-0.905128</td>\n      <td>-0.149886</td>\n      <td>-0.882138</td>\n      <td>-0.751823</td>\n      <td>-0.940477</td>\n      <td>-0.896964</td>\n      <td>-0.290764</td>\n      <td>-0.691552</td>\n      <td>-0.118042</td>\n      <td>...</td>\n      <td>0.469137</td>\n      <td>-0.357597</td>\n      <td>-0.914628</td>\n      <td>-0.360328</td>\n      <td>-0.485076</td>\n      <td>-0.818625</td>\n      <td>-0.905969</td>\n      <td>-0.832032</td>\n      <td>-0.350340</td>\n      <td>-0.970445</td>\n    </tr>\n    <tr>\n      <th>630</th>\n      <td>0</td>\n      <td>-0.985533</td>\n      <td>-0.799825</td>\n      <td>-0.996317</td>\n      <td>-0.970803</td>\n      <td>-0.994048</td>\n      <td>-0.998311</td>\n      <td>-0.872292</td>\n      <td>-0.915757</td>\n      <td>-0.809127</td>\n      <td>...</td>\n      <td>0.732931</td>\n      <td>-0.573425</td>\n      <td>-0.970355</td>\n      <td>-0.815885</td>\n      <td>-0.865671</td>\n      <td>-0.921566</td>\n      <td>-0.992767</td>\n      <td>-0.880016</td>\n      <td>-0.598787</td>\n      <td>-0.972266</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>0</td>\n      <td>-0.985393</td>\n      <td>-0.815414</td>\n      <td>-0.985267</td>\n      <td>-0.995134</td>\n      <td>-1.000000</td>\n      <td>-0.994933</td>\n      <td>-0.879133</td>\n      <td>-0.926900</td>\n      <td>-0.815704</td>\n      <td>...</td>\n      <td>0.714058</td>\n      <td>-0.585071</td>\n      <td>-0.978370</td>\n      <td>-0.862177</td>\n      <td>-0.746272</td>\n      <td>-0.916665</td>\n      <td>-0.992767</td>\n      <td>-0.883149</td>\n      <td>-0.633289</td>\n      <td>-0.968412</td>\n    </tr>\n  </tbody>\n</table>\n<p>632 rows × 1281 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.decomposition import PCA\ny = df[0].values\nx = df.drop([0],axis=1).values\nsm = SMOTE(random_state=1)\nX_res , Y_res = sm.fit_resample(x, y)\n\nX_train, X_test, y_train, y_test = train_test_split(X_res,Y_res,test_size=0.2,random_state=0)\nfr = PCA(n_components=100)\nfr.fit(X_train)\nX_train = fr.transform(X_train)\nX_test = fr.transform(X_test)\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(X_train)\nX_train_norm = scaler.transform(X_train)\nX_test_norm = scaler.transform(X_test)\n# fs = SelectKBest(chi2, k=250)\n# fs.fit(X_train_norm, y_train)\n# X_test_norm = fs.transform(X_test_norm)\n# X_train_norm = fs.transform(X_train_norm)","execution_count":154,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test\n","execution_count":155,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"'DataFrame' object is not callable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-155-6bee868e7ce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/plenoi/CMU_DataScience/master/lung_test.csv?fbclid=IwAR3Bo1ZxcS-_z2BqEX94ZCstw8bWArKZTl1AFMBmRHGgYk6SMjGLhoVa1Zk'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mXt_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mXt_test_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nparams = {\n    'C' : [1,2,4,8,16,32], # High C = Overfitting\n    'gamma' : [0.03125, 0.0600, 0.125, 0.25, 0.5, 1, 2, 4, 8, 15, 32] # High gamma = Overfitting\n}\nclf = GridSearchCV(SVC(),params, cv=10)\nclf.fit(X_train_norm, y_train)\nprint(\"Best params : \" + str(clf.best_params_))\nprint(\"10CV accuracy : \"+str(clf.best_score_*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\ny_predict = clf.predict(X_test_norm)\ntarget_names = ['negative', 'positive']\nsum(y_test == y_predict)/len(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ntarget_names = ['negative', 'positive']\nC = confusion_matrix(y_test,y_predict) \nC = C / C.astype(np.float).sum(axis=1)*100\nsns.heatmap(C, annot=True, fmt=\".2f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\nplt.ylabel(\"True Label\")\nplt.xlabel(\"Predicted Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_predict, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test\ndf_test = pd.read_csv('https://raw.githubusercontent.com/plenoi/CMU_DataScience/master/lung_test.csv?fbclid=IwAR3Bo1ZxcS-_z2BqEX94ZCstw8bWArKZTl1AFMBmRHGgYk6SMjGLhoVa1Zk',header=None)\nyt = df_test[0].values\nxt = df_test.drop([0],axis=1).values\nXt_test = fr.transform(xt)\nXt_test_norm = scaler.transform(Xt_test)\ny_predict = clf.predict(Xt_test_norm)\nsum(yt == y_predict)/len(yt)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}